{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a analizar los textos de las críticas dejadas por usuarios en el sitio metacritic.com para el juego \"The Legend of Zelda: Breath of the Wild \", y apuntar a discernir entre aquellas donde la nota final se encuentra por debajo o por encima de un cierto umbral. Si el modelo es exitoso, dado un texto, podría predecir correctamente si el mismo corresponde a una nota mayor o menor al umbral. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, leemos los datos de un archivo externo y los \"limpiamos\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>\\nSimply Amazing. Nuff said. This is the best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>I love how this game is so good, that triggerd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>\\nSimply breathtaking and stunning. Nintendo h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>\\nEste juego es la perfeccion en cuanto a jueg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>\\nStunning in every way, While everyone though...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                               text\n",
       "0     10  \\nSimply Amazing. Nuff said. This is the best ...\n",
       "1     10  I love how this game is so good, that triggerd...\n",
       "2     10  \\nSimply breathtaking and stunning. Nintendo h...\n",
       "3     10  \\nEste juego es la perfeccion en cuanto a jueg...\n",
       "4     10  \\nStunning in every way, While everyone though..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsDf = pd.read_csv('zeldareviews.csv', index_col = 0).drop(['name'], axis = 1)\n",
    "reviewsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTexts = reviewsDf['text']\n",
    "reviewTexts = reviewTexts.apply(lambda x: x.replace('\\r', '').replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en un conjunto de entrenamiento y uno de testeo (con una proporción de 75:25), y definimos los labels: van a ser positivo si el puntaje es mayor a 8 (es decir, un 9 o un 10), y negativo en caso contrario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsList = [text for text in reviewTexts]\n",
    "text_train = reviewsList[:int(len(reviewsList)*0.75)]\n",
    "y_train = [score > 8 for score in reviewsDf['score']][:int(len(reviewsList)*0.75)]\n",
    "text_test = reviewsList[int(len(reviewsList)*0.75)+1:]\n",
    "y_test = [score > 8 for score in reviewsDf['score']][int(len(reviewsList)*0.75)+1:]\n",
    "scores = [score for score in reviewsDf['score']][int(len(reviewsList)*0.75)+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos el proceso llevando el conjunto de palabras a un formato numérico para poder trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19406\n",
      "bag_of_words: <3495x19406 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 258867 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df = 1) #CountVectorizer lleva el texto a nros\n",
    "vect.fit(text_train)\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"bag_of_words: {}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora buscamos, para un modelo de regresión logística, el valor de C que lleva a un menor error, usando gridsearchCV de scikit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.89\n",
      "Best parameters:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter = 1000), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver cuántos errores y de qué tipo presenta el modelo, estudiamos la matriz de confusión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 385  275]\n",
      " [ 119 2716]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_labels = cross_val_predict(LogisticRegression(max_iter = 1000), X_train, y_train, cv=5)\n",
    "confusion = confusion_matrix(y_train, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el modelo que se eligió como mejor, y lo entrentamos con la data de entrenamiento.\n",
    "\n",
    "Luego, generamos las predicciones del conjunto de testeo y tomamos las métricas de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.49      0.34      0.40       125\n",
      "        True       0.92      0.96      0.94      1039\n",
      "\n",
      "    accuracy                           0.89      1164\n",
      "   macro avg       0.71      0.65      0.67      1164\n",
      "weighted avg       0.88      0.89      0.88      1164\n",
      "\n",
      "\n",
      " Confusion Matrix: \n",
      "[[ 42  83]\n",
      " [ 43 996]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter = 1000, C = 1) \n",
    "logreg.fit(X_train, y_train)\n",
    "X_test = vect.transform(text_test)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"\\n Confusion Matrix: \")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "El rendimiento del modelo es particularmente malo a la hora de clasificar falsos, es decir, reviews \"negativas\". Esto se da porque subimos el umbral para los casos \"negativos\" a un valor de 8, lo cual no llega a ser suficientemente distinguible de los valores \"positivos\" (puntaje de 9 o 10) como para que el modelo lo detecte (hasta para un humano resulta difícil diferenciar un 8 de un 9). El problema es que bajar el límite nos dejaría menos data para trabajar, ya que el número de casos negativos sería muy bajo.\n",
    "\n",
    "Si bien no es un buen modelo para diferencias tan sutiles, si lo es para detectar reviews muy positivas (de 9 o 10), tienendo un 92% de precisión y un 96% de recall, es decir, estamos detectando el 96% de los casos deseados. \n",
    "\n",
    "Este modelo sería entonces de utilidad en caso de que se quiera identificar principalmente a las reviews muy positivas, por ejemplo, para medir el interés en contenido adicional relacionado al juego.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra alternativa es subir el umbral, y diferenciar los 10 de el resto. Esto aumentaría la precisión de detección de los falsos, a costa de bajar la precisión de los verdaderos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sería interesante probar el modelo en reviews de otros juegos. Lo más seguro es que la performance sea bastante pobre, principalmente porque los vocabularios utilizados difieren, y lo que es positivo para un juego es negativo para otro.\n",
    "\n",
    "Si se quisiera generalizar, se debería utilizar data de entrenamiento perteneciente a un conjunto lo más diverso posible de juegos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
